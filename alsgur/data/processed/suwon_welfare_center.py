import pandas as pd
import os
import json
from haversine import haversine

# ==========================================
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (ì´ˆê¸°í™”)
# ==========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# íŒŒì¼ ì„¤ì • (ìˆ˜ì›, ê°•ë¦‰, íŒŒì£¼)
CSV_CONFIGS = [
    {
        "region": "ìˆ˜ì›ì‹œ",
        "path": "data/raw/ê²½ê¸°ë„_ìˆ˜ì›ì‹œ_ë…¸ì¸ë³µì§€ì‹œì„¤í˜„í™©_20250411.csv",
        "encoding": "cp949" 
    },
    {
        "region": "ê°•ë¦‰ì‹œ",
        "path": "data/raw/ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ_ë…¸ì¸ë³µì§€ì‹œì„¤í˜„í™©_20250305.csv",
        "encoding": "cp949"
    },
    {
        "region": "íŒŒì£¼ì‹œ",
        "path": "data/raw/ê²½ê¸°ë„ íŒŒì£¼ì‹œ_ë…¸ì¸ë³µì§€ì‹œì„¤í˜„í™©_20251202.csv",
        "encoding": "utf-8"
    }
]

def _standardize_columns(df):
    """ì»¬ëŸ¼ëª… í‘œì¤€í™” ë° ì „ì²˜ë¦¬ (ë‚´ë¶€ í•¨ìˆ˜)"""
    rename_map = {}
    
    # ì‹œì„¤êµ¬ë¶„ ë§¤í•‘
    if 'ì‹œì„¤ì¢…ë¥˜' in df.columns: rename_map['ì‹œì„¤ì¢…ë¥˜'] = 'ì‹œì„¤êµ¬ë¶„'       
    elif 'ì œê³µì„œë¹„ìŠ¤' in df.columns: rename_map['ì œê³µì„œë¹„ìŠ¤'] = 'ì‹œì„¤êµ¬ë¶„'   
    elif 'ì‹œì„¤ìœ í˜•' in df.columns: rename_map['ì‹œì„¤ìœ í˜•'] = 'ì‹œì„¤êµ¬ë¶„'
    
    # ì£¼ì†Œ/ì¢Œí‘œ ë§¤í•‘
    if 'ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ' in df.columns: rename_map['ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ'] = 'ì£¼ì†Œ'
    elif 'ë„ë¡œëª…ì£¼ì†Œ' in df.columns: rename_map['ë„ë¡œëª…ì£¼ì†Œ'] = 'ì£¼ì†Œ'
    if 'WGS84ìœ„ë„' in df.columns: rename_map['WGS84ìœ„ë„'] = 'ìœ„ë„'
    if 'WGS84ê²½ë„' in df.columns: rename_map['WGS84ê²½ë„'] = 'ê²½ë„'

    if rename_map:
        df = df.rename(columns=rename_map)
        
    # í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    if 'ì‹œì„¤êµ¬ë¶„' not in df.columns:
        df['ì‹œì„¤êµ¬ë¶„'] = df['ì‹œì„¤ëª…'] # ì‹œì„¤êµ¬ë¶„ ì—†ìœ¼ë©´ ì´ë¦„ìœ¼ë¡œ ëŒ€ì²´
        
    return df

def load_data():
    """ë°ì´í„° ë¡œë“œ ë° í†µí•©"""
    merged_list = []
    print("ğŸš€ [System] ë°ì´í„° ë¡œë”© ì¤‘...")
    
    for config in CSV_CONFIGS:
        full_path = os.path.normpath(os.path.join(BASE_DIR, "../../", config['path']))
        try:
            df = pd.read_csv(full_path, encoding=config.get('encoding', 'cp949'))
            df = _standardize_columns(df)
            
            # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
            if 'ìœ„ë„' in df.columns and 'ê²½ë„' in df.columns:
                df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
                df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
                df = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])
                
                df['region_source'] = config['region']
                merged_list.append(df)
        except Exception as e:
            print(f"âš ï¸ {config['region']} ë¡œë“œ ì‹¤íŒ¨: {e}")

    if merged_list:
        final_df = pd.concat(merged_list, ignore_index=True)
        final_df = final_df.fillna('') # JSON ë³€í™˜ ì‹œ NaN ì—ëŸ¬ ë°©ì§€
        print(f"âœ… [System] ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ì´ {len(final_df)}ê°œ ì‹œì„¤)")
        return final_df
    else:
        return pd.DataFrame() # ë¹ˆ í”„ë ˆì„ ë°˜í™˜

# ì „ì—­ ë³€ìˆ˜ë¡œ ë°ì´í„° ë¡œë“œ (ì„œë²„ ì‹¤í–‰ ì‹œ 1íšŒë§Œ ë¡œë“œë¨)
GLOBAL_DF = load_data()


# ==========================================
# 2. AI ì¶”ì²œ ë¡œì§ (ì™¸ë¶€ í˜¸ì¶œìš© í•¨ìˆ˜)
# ==========================================
def get_ai_recommendations(user_lat, user_lon, user_interest='ê±´ê°•ì¼€ì–´', max_dist_km=50, limit=5):
    """
    ë°±ì—”ë“œì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    :param user_lat: ì‚¬ìš©ì ìœ„ë„
    :param user_lon: ì‚¬ìš©ì ê²½ë„
    :param user_interest: ê´€ì‹¬ì‚¬ ('ê±´ê°•ì¼€ì–´', 'ìƒí™œë„ì›€', 'ì£¼ê±°ì§€ì›')
    :return: JSON í˜¸í™˜ Dictionary
    """
    if GLOBAL_DF.empty:
        return {"status": "error", "message": "ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    user_pos = (user_lat, user_lon)
    
    # ë³µì‚¬ë³¸ ìƒì„± (ì›ë³¸ ë³´ì¡´)
    df = GLOBAL_DF.copy()
    
    # 1. ê±°ë¦¬ ê³„ì‚°
    df['dist_km'] = df.apply(lambda x: haversine(user_pos, (x['ìœ„ë„'], x['ê²½ë„']), unit='km'), axis=1)
    
    # 2. ê´€ì‹¬ì‚¬ í•„í„°ë§ ë¡œì§
    interest_map = {
        'ê±´ê°•ì¼€ì–´': ['ì˜ë£Œ', 'ìš”ì–‘', 'ë³‘ì›', 'ì¹˜ë§¤', 'ê°„í˜¸'],
        'ìƒí™œë„ì›€': ['ì¬ê°€', 'ì£¼ê°„ë³´í˜¸', 'ë°©ë¬¸', 'ëŒë´„', 'ë³µì§€ê´€'],
        'ì£¼ê±°ì§€ì›': ['ì£¼ê±°', 'ì–‘ë¡œ', 'ê³µë™ìƒí™œ', 'ì…ì†Œ']
    }
    keywords = interest_map.get(user_interest, [])
    
    def calculate_score(row):
        score = 10 / (row['dist_km'] + 0.5) # ê±°ë¦¬ ì ìˆ˜
        
        # í‚¤ì›Œë“œ ê°€ì‚°ì 
        content = (str(row['ì‹œì„¤êµ¬ë¶„']) + str(row['ì‹œì„¤ëª…'])).replace("nan", "")
        for k in keywords:
            if k in content:
                score += 20
                break
        return score

    df['ai_score'] = df.apply(calculate_score, axis=1)
    
    # 3. ê²°ê³¼ ì •ë ¬ ë° í¬ë§·íŒ…
    results = df[df['dist_km'] <= max_dist_km] \
                .sort_values(by='ai_score', ascending=False) \
                .head(limit)
    
    if results.empty:
        return {"status": "empty", "message": "ê·¼ì²˜ì— ì í•©í•œ ì‹œì„¤ì´ ì—†ìŠµë‹ˆë‹¤."}
    
    data_list = []
    for _, row in results.iterrows():
        data_list.append({
            "name": row['ì‹œì„¤ëª…'],
            "category": row['ì‹œì„¤êµ¬ë¶„'],
            "region": row['region_source'],
            "address": row['ì£¼ì†Œ'],
            "latitude": row['ìœ„ë„'],
            "longitude": row['ê²½ë„'],
            "distance_km": round(row['dist_km'], 1),
            "match_score": round(row['ai_score'], 1),
            "phone": row.get('ì „í™”ë²ˆí˜¸', '') # ì „í™”ë²ˆí˜¸ ìˆìœ¼ë©´ ì¶”ê°€
        })
        
    return {
        "status": "success", 
        "request_interest": user_interest,
        "count": len(data_list),
        "data": data_list
    }

# ==========================================
# 3. ì‹¤í–‰ë¶€ (ì´ íŒŒì¼ ì§ì ‘ ì‹¤í–‰ ì‹œ JSON ìƒì„±)
# ==========================================
if __name__ == "__main__":
    print("\n--- ğŸ’¾ ë°±ì—”ë“œ ì „ë‹¬ìš© JSON íŒŒì¼ ìƒì„± ì¤‘... ---")
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_output = {
        "description": "ë…¸ì¸ ë³µì§€ ì‹œì„¤ AI ì¶”ì²œ ê²°ê³¼ ìƒ˜í”Œ",
        "scenarios": {
            "case_suwon_health": get_ai_recommendations(37.266, 127.000, 'ê±´ê°•ì¼€ì–´'),
            "case_gangneung_life": get_ai_recommendations(37.751, 128.876, 'ìƒí™œë„ì›€'),
            "case_paju_house": get_ai_recommendations(37.760, 126.779, 'ì£¼ê±°ì§€ì›')
        }
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open("recommendation_results.json", "w", encoding='utf-8') as f:
        json.dump(sample_output, f, ensure_ascii=False, indent=4)
        
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {os.path.abspath('recommendation_results.json')}")
    print("ğŸ‘‰ ì´ íŒŒì¼ê³¼ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë°±ì—”ë“œ ê°œë°œìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.")